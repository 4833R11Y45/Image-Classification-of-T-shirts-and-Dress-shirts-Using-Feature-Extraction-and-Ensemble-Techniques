{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "itEmT7rhqgrb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from skimage import feature, filters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "import cv2\n",
        "from skimage.feature import hog\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0RkIfMTEq9yJ"
      },
      "outputs": [],
      "source": [
        "def extract_features(images):\n",
        "    features = []\n",
        "    \n",
        "    for image in images:\n",
        "        # Resize the image to at least 16x16 pixels\n",
        "        resized_image = cv2.resize(image, (16, 16))\n",
        "\n",
        "        # Normalize the pixel values to 0-1\n",
        "        normalized_image = resized_image / 255.0\n",
        "\n",
        "        # Compute the HoG features\n",
        "        hog_features = hog(normalized_image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                           cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
        "        \n",
        "        # Perform Canny Edge Detection on the normalized image\n",
        "        edges = cv2.Canny((normalized_image * 255).astype('uint8'), 100, 200)\n",
        "\n",
        "        # Flatten the edges image to a 1D array\n",
        "        edges_flat = edges.flatten()\n",
        "\n",
        "        # Combine the HoG features and Canny edges into a single feature vector\n",
        "        combined_features = np.concatenate((hog_features, edges_flat))\n",
        "\n",
        "        features.append(combined_features)\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X, Y, epochs=10):\n",
        "    # Extract features from training data\n",
        "    x_train_features = extract_features(X)\n",
        "\n",
        "    # Set up classifiers\n",
        "    knn = KNeighborsClassifier()\n",
        "    rf = RandomForestClassifier()\n",
        "\n",
        "    # Set up voting classifier\n",
        "    voting_classifier = VotingClassifier(estimators=[('knn', knn), ('rf', rf)], voting='hard')\n",
        "\n",
        "    # Set up parameter grid for hyperparameter tuning\n",
        "    param_grid = {'knn__n_neighbors': [3, 5, 7], 'rf__n_estimators': [50, 100, 200]}\n",
        "\n",
        "    # Perform grid search cross-validation\n",
        "    grid_search = GridSearchCV(voting_classifier, param_grid, cv=5)\n",
        "    grid_search.fit(x_train_features, Y)\n",
        "\n",
        "    # Get best estimator and best parameters\n",
        "    best_classifier = grid_search.best_estimator_\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Train final model with best parameters and specified number of epochs\n",
        "    for _ in range(epochs):\n",
        "        best_classifier.fit(x_train_features, Y)\n",
        "\n",
        "    return best_classifier, best_params"
      ],
      "metadata": {
        "id": "0R6ADAQteQrn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4at3RLrJrgbb"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load training data\n",
        "    Xtr = np.loadtxt(\"/content/drive/MyDrive/TrainData.csv\")\n",
        "    Ytr = np.loadtxt(\"/content/drive/MyDrive/TrainLabels.csv\")\n",
        "\n",
        "    # Reshape training data to 2D array\n",
        "    Xtr = Xtr.reshape((Xtr.shape[0], -1))\n",
        "\n",
        "    # Train the model\n",
        "    trained_model, best_parameters = train_model(Xtr, Ytr)\n",
        "\n",
        "    # Save the final model\n",
        "    pickle.dump(trained_model, open(\"myModel.pkl\", \"wb\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}